{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8725b68f",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [2]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45365ec",
   "metadata": {
    "papermill": {
     "duration": 0.003074,
     "end_time": "2024-12-26T17:44:35.601976",
     "exception": false,
     "start_time": "2024-12-26T17:44:35.598902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train and Benchmark and Neural Decoder  with Viterbi Decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41867e2c",
   "metadata": {
    "papermill": {
     "duration": 0.002689,
     "end_time": "2024-12-26T17:44:35.607496",
     "exception": false,
     "start_time": "2024-12-26T17:44:35.604807",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6c0fd25",
   "metadata": {
    "papermill": {
     "duration": 0.002755,
     "end_time": "2024-12-26T17:44:35.612759",
     "exception": false,
     "start_time": "2024-12-26T17:44:35.610004",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8633f11e",
   "metadata": {
    "papermill": {
     "duration": 0.00251,
     "end_time": "2024-12-26T17:44:35.618335",
     "exception": false,
     "start_time": "2024-12-26T17:44:35.615825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook contains pipeline how to train a neural decoder model for decoding convolution code over AWGN Channel at 1/2-RSC signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b15f4ca",
   "metadata": {
    "papermill": {
     "duration": 0.002475,
     "end_time": "2024-12-26T17:44:35.623329",
     "exception": false,
     "start_time": "2024-12-26T17:44:35.620854",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0bf2024",
   "metadata": {
    "papermill": {
     "duration": 0.002486,
     "end_time": "2024-12-26T17:44:35.628340",
     "exception": false,
     "start_time": "2024-12-26T17:44:35.625854",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e4f373d",
   "metadata": {
    "papermill": {
     "duration": 0.002428,
     "end_time": "2024-12-26T17:44:35.633255",
     "exception": false,
     "start_time": "2024-12-26T17:44:35.630827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d380380e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T17:44:35.639055Z",
     "iopub.status.busy": "2024-12-26T17:44:35.638805Z",
     "iopub.status.idle": "2024-12-26T17:44:38.202766Z",
     "shell.execute_reply": "2024-12-26T17:44:38.202252Z"
    },
    "papermill": {
     "duration": 2.56816,
     "end_time": "2024-12-26T17:44:38.203855",
     "exception": false,
     "start_time": "2024-12-26T17:44:35.635695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 23:14:36.629355: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-26 23:14:36.848061: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 23:14:37.516732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import commpy as cp\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from deepcom.model import NRSCDecoder           # Neural Decoder Model\n",
    "\n",
    "from deepcom.metrics import BER, BLER           # metrics to benchmark Neural Decoder Model\n",
    "\n",
    "from deepcom.utils import corrupt_signal        # simulate a AWGN Channel\n",
    "\n",
    "from deepcom.dataset import create_dataset      # Create synthetic dataset\n",
    "\n",
    "from deepcom.dataset import data_genenerator    # data loader for Tensorflow\n",
    "\n",
    "import  matplotlib.pyplot  as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266dca7d",
   "metadata": {
    "papermill": {
     "duration": 0.002485,
     "end_time": "2024-12-26T17:44:38.209301",
     "exception": false,
     "start_time": "2024-12-26T17:44:38.206816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Hyper-paramemeters for the experiment\n",
    "# Number of training data\n",
    "\n",
    "BLOCK_LEN = 10\n",
    "\n",
    "NUM_TRAINING_DATA = 1200\n",
    "\n",
    "NUM_TESTING_DATA  = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f2385",
   "metadata": {
    "papermill": {
     "duration": 0.002471,
     "end_time": "2024-12-26T17:44:38.214287",
     "exception": false,
     "start_time": "2024-12-26T17:44:38.211816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Communication Algo via Deep Learning\n",
    "#(page 5, last paragraph)\n",
    "\n",
    "NOISE_TYPE ='awgn'\n",
    "SNR_train = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82ead2d",
   "metadata": {
    "papermill": {
     "duration": 0.002664,
     "end_time": "2024-12-26T17:44:38.219862",
     "exception": false,
     "start_time": "2024-12-26T17:44:38.217198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Network Architectures\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "NUM_HIDDEN_UNITS = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2b78a6",
   "metadata": {
    "papermill": {
     "duration": 0.002599,
     "end_time": "2024-12-26T17:44:38.225169",
     "exception": false,
     "start_time": "2024-12-26T17:44:38.222570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hyper-parameters for training\n",
    "\n",
    "BATCH_SIZE = 500       # depends on size of GPU, should be a factor of num_data\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "DROPOUT_RATE= 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3c1a8",
   "metadata": {
    "papermill": {
     "duration": 0.002629,
     "end_time": "2024-12-26T17:44:38.230452",
     "exception": false,
     "start_time": "2024-12-26T17:44:38.227823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#\n",
    "#\n",
    "# CONSTRAINT_LEN = 3     # num of shifts in Conv. Encoder\n",
    "# TRACE_BACK_DEPTH = 15  # (?) a parameter Viterbi Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a5f21",
   "metadata": {
    "papermill": {
     "duration": 0.002856,
     "end_time": "2024-12-26T17:44:38.235809",
     "exception": false,
     "start_time": "2024-12-26T17:44:38.232953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generate Synthetic Dataset for training/evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8043f4ae",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d894bb71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T17:44:38.242801Z",
     "iopub.status.busy": "2024-12-26T17:44:38.242406Z",
     "iopub.status.idle": "2024-12-26T17:44:38.580668Z",
     "shell.execute_reply": "2024-12-26T17:44:38.579956Z"
    },
    "papermill": {
     "duration": 0.34272,
     "end_time": "2024-12-26T17:44:38.581485",
     "exception": true,
     "start_time": "2024-12-26T17:44:38.238765",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CONSTRAINT_LEN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#  Generator Matrix (octal representation)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m G \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0o7\u001b[39m, \u001b[38;5;241m0o5\u001b[39m]]) \n\u001b[0;32m----> 7\u001b[0m M \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mCONSTRAINT_LEN\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      9\u001b[0m trellis \u001b[38;5;241m=\u001b[39m Trellis(M, G, feedback\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0o7\u001b[39m, code_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrsc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CONSTRAINT_LEN' is not defined"
     ]
    }
   ],
   "source": [
    "from commpy.channelcoding import Trellis\n",
    "\n",
    "#  Generator Matrix (octal representation)\n",
    "\n",
    "G = np.array([[0o7, 0o5]]) \n",
    "\n",
    "M = np.array([CONSTRAINT_LEN - 1])\n",
    "\n",
    "trellis = Trellis(M, G, feedback=0o7, code_type='rsc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d36148d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Create dataset \n",
    "\n",
    "print('Creating training data....')\n",
    "\n",
    "# X_train shape = [NUM_TRAINING_DATA, BLOCK_LENGTH, 2]\n",
    "# Y_train shape = [NUM_TRAINING_DATA, BLOCK_LENGTH, 1]\n",
    "\n",
    "X_train, Y_train = create_dataset(\n",
    "    NUM_TRAINING_DATA, \n",
    "    BLOCK_LEN, \n",
    "    trellis, \n",
    "    noise_type=NOISE_TYPE, snr=SNR_train, seed=2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c30ba4c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "\n",
    "print('Creating testing data....')\n",
    "# X_test shape = [NUM_TESTING_DATA, BLOCK_LENGTH, 2]\n",
    "# Y_test shape = [NUM_TESTING_DATA, BLOCK_LENGTH, 1]\n",
    "\n",
    "X_test, Y_test = create_dataset(\n",
    "    NUM_TESTING_DATA, \n",
    "    BLOCK_LEN, \n",
    "    trellis, \n",
    "    noise_type=NOISE_TYPE, snr=SNR_train, seed=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90578cc6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "\n",
    "print('Number of training sequences {}'.format(len(X_train)))\n",
    "print('Number of testing sequences {}'.format(len(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5143308d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b08514",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Define Neural Decoder Model\n",
    "# Construct Neural Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6060c632",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(None, 2))\n",
    "\n",
    "outputs = NRSCDecoder(\n",
    "    inputs, \n",
    "    is_training=True, \n",
    "    num_layers=NUM_LAYERS, \n",
    "    hidden_units=NUM_HIDDEN_UNITS, \n",
    "    dropout=DROPOUT_RATE)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cf1051",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Set up training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9a6a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile('adam', 'binary_crossentropy', [BER])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc9530b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Start Training/Eval Pipeline\n",
    "# Set up Data Loader using tf.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79f9ec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = data_genenerator(X_train, Y_train, BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_set = data_genenerator(X_test, Y_test, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e72341",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Backup best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a972ac8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "backup = tf.keras.callbacks.ModelCheckpoint(                     \n",
    "  filepath='BiGRU.keras',\n",
    "  monitor='val_loss',\n",
    "  save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3e16c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Stop training early if the model seems to overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb52fe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0,\n",
    "    patience=3,\n",
    "    verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c19bf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_set, \n",
    "    steps_per_epoch=len(X_train) // BATCH_SIZE, \n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(X_test) // BATCH_SIZE,\n",
    "    callbacks=[early_stopping, backup],\n",
    "    epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94612424",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#\n",
    "#\n",
    "# model = tf.keras.models.load_model('BiGRU.hdf5',{'BER': BER})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325de79e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Count of the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63bfa95",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = range(1, len(history.history['loss']) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32507d39",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Visualize loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16831445",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(epochs, history.history['loss'], 'r--')\n",
    "plt.plot(epochs, history.history['val_loss'], 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57672200",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Benchmark Neural Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc882d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def benchmark_neural_decoder(noisy_inputs, labels):\n",
    "\n",
    "    # Set up data generator\n",
    "    Y = np.reshape(labels, (-1, BLOCK_LEN, 1))\n",
    "    X = np.reshape(np.array(noisy_inputs)[:, :2*BLOCK_LEN], (-1, BLOCK_LEN, 2))\n",
    "    test_set = data_genenerator(X, Y, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Make predictions in batch\n",
    "    decoded_bits = model.predict(\n",
    "        test_set,\n",
    "        steps=len(Y) // BATCH_SIZE)\n",
    "\n",
    "    # Compute hamming distances\n",
    "    original_bits = np.reshape(Y, (-1, BLOCK_LEN)).astype(int)\n",
    "    decoded_bits =  np.reshape(np.round(decoded_bits), (-1, BLOCK_LEN)).astype(int)\n",
    "    hamming_dist = np.not_equal(original_bits, decoded_bits)\n",
    "\n",
    "    return np.sum(hamming_dist, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6c000",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "def benchmark_viterbi(message_bits, noisy_bits, sigma):\n",
    "    \n",
    "    # make fair comparison between (100, 204) convolutional code and RNN decoder\n",
    "    # Reference: Author's code\n",
    "\n",
    "    noisy_bits[-2*int(M):] = 0\n",
    "    \n",
    "    # Viterbi Decoder on Conv. Code\n",
    "    decoded_bits = cp.channelcoding.viterbi_decode(\n",
    "        coded_bits=noisy_bits.astype(float), \n",
    "        trellis=trellis,\n",
    "        tb_depth=TRACE_BACK_DEPTH,\n",
    "        decoding_type='unquantized')\n",
    "\n",
    "    # Number of bit errors (hamming distance)\n",
    "    hamming_dist = cp.utilities.hamming_dist(\n",
    "        message_bits.astype(int),\n",
    "        decoded_bits[:-int(M)])\n",
    "    return hamming_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b536cbb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# #################################################################\n",
    "# For every SNR_db, we generates new noisy signals\n",
    "# for fair comparision.\n",
    "# #################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a35e8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_noisy_input(message_bits, trellis, sigma):\n",
    "    # Encode message bit\n",
    "    coded_bits = cp.channelcoding.conv_encode(message_bits, trellis)\n",
    "    \n",
    "    # Corrupt message on BAWGN Channel\n",
    "    coded_bits = corrupt_signal(coded_bits, noise_type='awgn', sigma=sigma)\n",
    "    return coded_bits, message_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e96d92d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "viterbiBERs, viterbiBLERs = [], []\n",
    "neuralBERs, neuralBLERs = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fe00ee",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pool = mp.Pool(processes=mp.cpu_count())\n",
    "\n",
    "labels = np.reshape(Y_test, (-1, BLOCK_LEN)).astype(int)\n",
    "\n",
    "try: \n",
    "    SNRs  = np.linspace(0, 7.0, 8)\n",
    "    for snr in SNRs:\n",
    "        snr_linear = snr + 10 * np.log10(1./2.)\n",
    "        sigma = np.sqrt(1. / (2. * 10 **(snr_linear / 10.)))\n",
    "        print('[SNR]={:.2f}'.format(snr))\n",
    "        \n",
    "        # Generates new noisy signals\n",
    "        result = pool.starmap(\n",
    "            func=generate_noisy_input,  \n",
    "            iterable=[(msg_bits, trellis, sigma) for msg_bits in labels])\n",
    "        X, Y =  zip(*result)\n",
    "        \n",
    "        # #################################################################\n",
    "        # BENCHMARK NEURAL DECODER \n",
    "        # #################################################################\n",
    "        nn_start = time.time()\n",
    "        hamm_dists = benchmark_neural_decoder(X, Y)\n",
    "        nn_ber = sum(hamm_dists) / np.product(np.shape(Y))\n",
    "        nn_bler = np.count_nonzero(hamm_dists) / len(Y)\n",
    "        neuralBERs.append(nn_ber)\n",
    "        neuralBLERs.append(nn_bler)            \n",
    "        print('\tNeural Decoder:  [BER]={:5.7f} [BLER]={:5.3f} -- {:3.3f}s'.format(\n",
    "            nn_ber, nn_bler, time.time() - nn_start)) \n",
    "        # #################################################################\n",
    "        # BENCHMARK VITERBI DECODER \n",
    "        # #################################################################\n",
    "        vi_start = time.time()\n",
    "        hamm_dists = pool.starmap(benchmark_viterbi, [(y, x, sigma) for x, y in zip(X, Y)])\n",
    "        ber = sum(hamm_dists) / np.product(np.shape(Y))\n",
    "        bler = np.count_nonzero(hamm_dists) / len(Y)\n",
    "        viterbiBERs.append(ber)\n",
    "        viterbiBLERs.append(bler)\n",
    "        print('\tViterbi Decoder: [BER]={:5.7f} [BLER]={:5.3f} -- {:3.3f}s'.format(\n",
    "              ber, bler, time.time() - vi_start))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e080e427",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Result\n",
    "# ###################################\n",
    "# Plot Bit Error Rate (BER) Curve\n",
    "# ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df16a1e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Block Length = 100 || Data rate = 1/2', fontsize=14)\n",
    "plt.semilogy(SNRs, neuralBERs, '-vr')\n",
    "plt.semilogy(SNRs, viterbiBERs, 's--')\n",
    "plt.legend(['N-RSC (SNR_train=0 dB)', 'Viterbi'], fontsize=16)\n",
    "plt.xlabel('SNR', fontsize=16)\n",
    "plt.xlim(xmin=SNRs[0], xmax=SNRs[-1])  # this line\n",
    "plt.ylabel('BER', fontsize=16)\n",
    "plt.grid(True, which='both')\n",
    "plt.savefig('result_ber_block_length_1000_snr0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c9746",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# ###################################\n",
    "# Plot Block Error Rate (BLER) Curve\n",
    "# ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31fb8f3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Block Length = 100 || Data rate = 1/2', fontsize=14)\n",
    "plt.semilogy(SNRs, neuralBLERs, '-vr')\n",
    "plt.semilogy(SNRs, viterbiBLERs, 's--')\n",
    "plt.ylabel('BLER', fontsize=16)\n",
    "plt.xlabel('SNR', fontsize=16)\n",
    "plt.legend(['N-RSC (SNR_train=0 dB)', 'Viterbi'], fontsize=16)\n",
    "plt.xlim(xmin=SNRs[0], xmax=SNRs[-1])  # this line\n",
    "plt.grid(True, which='both')\n",
    "plt.savefig('result_bler_block_length_1000_snr0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a20d3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##  Benchmark on K = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2290b4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, Y_test = create_dataset(NUM_TESTING_DATA, 1000, trellis, snr=0.0, seed=1111)\n",
    "viterbiBERs, viterbiBLERs = [], []\n",
    "neuralBERs, neuralBLERs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a4a7a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pool = mp.Pool(processes=mp.cpu_count())\n",
    "\n",
    "labels = np.reshape(Y_test, (-1, BLOCK_LEN)).astype(int)\n",
    "\n",
    "try: \n",
    "    SNRs  = np.linspace(0, 7.0, 8)\n",
    "    for snr in SNRs:\n",
    "        snr_linear = snr + 10 * np.log10(1./2.)\n",
    "        sigma = np.sqrt(1. / (2. * 10 **(snr_linear / 10.)))\n",
    "        print('[SNR]={:.2f}'.format(snr))\n",
    "        \n",
    "        # Generates new noisy signals\n",
    "        result = pool.starmap(\n",
    "            func=generate_noisy_input,  \n",
    "            iterable=[(msg_bits, trellis, sigma) for msg_bits in labels])\n",
    "        X, Y =  zip(*result)\n",
    "        \n",
    "        # #################################################################\n",
    "        # BENCHMARK NEURAL DECODER \n",
    "        # #################################################################\n",
    "        nn_start = time.time()\n",
    "        hamm_dists = benchmark_neural_decoder(X, Y)\n",
    "        nn_ber = sum(hamm_dists) / np.product(np.shape(Y))\n",
    "        nn_bler = np.count_nonzero(hamm_dists) / len(Y)\n",
    "        neuralBERs.append(nn_ber)\n",
    "        neuralBLERs.append(nn_bler)            \n",
    "        print('\tNeural Decoder:  [BER]={:5.7f} [BLER]={:5.3f} -- {:3.3f}s'.format(\n",
    "            nn_ber, nn_bler, time.time() - nn_start)) \n",
    "        # #################################################################\n",
    "        # BENCHMARK VITERBI DECODER \n",
    "        # #################################################################\n",
    "        vi_start = time.time()\n",
    "        hamm_dists = pool.starmap(benchmark_viterbi, [(y, x, sigma) for x, y in zip(X, Y)])\n",
    "        ber = sum(hamm_dists) / np.product(np.shape(Y))\n",
    "        bler = np.count_nonzero(hamm_dists) / len(Y)\n",
    "        viterbiBERs.append(ber)\n",
    "        viterbiBLERs.append(bler)\n",
    "        print('\tViterbi Decoder: [BER]={:5.7f} [BLER]={:5.3f} -- {:3.3f}s'.format(\n",
    "              ber, bler, time.time() - vi_start))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228943a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# ###################################\n",
    "# Plot Bit Error Rate (BER) Curve\n",
    "# ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef38d82",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Block Length = 100 || Data rate = 1/2', fontsize=14)\n",
    "plt.semilogy(SNRs, neuralBERs, '-vr')\n",
    "plt.semilogy(SNRs, viterbiBERs, 's--')\n",
    "plt.legend(['N-RSC (SNR_train=0 dB)', 'Viterbi'], fontsize=16)\n",
    "plt.xlabel('SNR', fontsize=16)\n",
    "plt.xlim(xmin=SNRs[0], xmax=SNRs[-1])  # this line\n",
    "plt.ylabel('BER', fontsize=16)\n",
    "plt.grid(True, which='both')\n",
    "plt.savefig('result_ber_block_length_1000_snr0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c492a8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# ###################################\n",
    "# Plot Block Error Rate (BLER) Curve\n",
    "# ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab517a09",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Block Length = 100 || Data rate = 1/2', fontsize=14)\n",
    "plt.semilogy(SNRs, neuralBLERs, '-vr')\n",
    "plt.semilogy(SNRs, viterbiBLERs, 's--')\n",
    "plt.ylabel('BLER', fontsize=16)\n",
    "plt.xlabel('SNR', fontsize=16)\n",
    "plt.legend(['N-RSC (SNR_train=0 dB)', 'Viterbi'], fontsize=16)\n",
    "plt.xlim(xmin=SNRs[0], xmax=SNRs[-1])  # this line\n",
    "plt.grid(True, which='both')\n",
    "plt.savefig('result_bler_block_length_1000_snr0.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.336937,
   "end_time": "2024-12-26T17:44:39.200561",
   "environment_variables": {},
   "exception": true,
   "input_path": "turbo-nn/reproduce_result.ipynb",
   "output_path": "turbo-nn/reports/reproduce_result_output.ipynb",
   "parameters": {},
   "start_time": "2024-12-26T17:44:34.863624",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
